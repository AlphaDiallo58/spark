
# Sentiment Analysis with Apache Spark

## Main Objective

The primary goal of this project is to utilize Apache Spark for distributing our computations. In an era where data is multiplying exponentially (referred to as Big Data), distributed processing has become essential for optimizing our calculations and managing machine resources efficiently.

## Files Included

- `analyse_de_sentiment_avec_spark.ipynb`: The Jupyter notebook where the sentiment analysis is implemented.
- `noclass.json`: Data file for unclassified data.
- `test.json`: Test data file.
- `train.json`: Training data file.

## Description

In this notebook, I implemented sentiment analysis using Apache Spark for large-scale data processing and analysis. It includes preprocessing steps, text vectorization, and classification to identify the sentiments expressed in the data.

## Usage

To run this project, you need to have Apache Spark installed and running. Open the `analyse_de_sentiment_avec_spark.ipynb` notebook and follow the steps for preprocessing, vectorizing, and classifying the sentiment of the input data.

